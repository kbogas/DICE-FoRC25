{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example setup for using your own data\n",
    "\n",
    "Here we show an example on using your own data for classification.\n",
    "\n",
    "We will use the 20newsgroup data, which is inherently multiclass, but will morph it accordingly.\n",
    "\n",
    "To run this file, we assume that an Ollama server is up and running at the default ports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# Keeping a subgroup of the data for speed\n",
    "cats = [\"alt.atheism\", \"sci.med\", \"talk.politics.guns\"]\n",
    "to_remove = (\"headers\", \"footers\", \"quotes\")\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=cats, remove=to_remove)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=cats, remove=to_remove)\n",
    "all_labels_list = newsgroups_test.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1620 (1620, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# We use OHE to morph it into a \"multi-label\" problem.\n",
    "ohe = OneHotEncoder()\n",
    "y_train = ohe.fit_transform(newsgroups_train.target.reshape(-1,1)).toarray()\n",
    "y_test = ohe.transform(newsgroups_test.target.reshape(-1,1)).toarray()\n",
    "\n",
    "X_train = np.array(newsgroups_train['data'])\n",
    "X_test = np.array(newsgroups_test['data'])\n",
    "\n",
    "print(len(X_train), y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import LLM_NN\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are a helpful annotator for a newsgroup agency.\n",
    "Given the context of a news file you have to categorize the file into\n",
    "one of its related categories.\n",
    "These are the contents of the file:\n",
    "{sample_text}.\n",
    "\n",
    "Select among these labels from other most similar files with their relevance: {similar_labels_freq}.\n",
    "\"\"\"\n",
    "\n",
    "model = LLM_NN(label_list=all_labels_list, prompt=prompt, threshold=0.1, top_k=11)\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting on test...: 100%|██████████| 10/10 [00:04<00:00,  2.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# For speed\n",
    "num_to_check = 10\n",
    "y_pred = model.predict(X_test[:num_to_check])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40         3\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       0.50      0.67      0.57         3\n",
      "\n",
      "    accuracy                           0.70        10\n",
      "   macro avg       0.67      0.67      0.66        10\n",
      "weighted avg       0.70      0.70      0.69        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# We transform it back to multi-class\n",
    "print(classification_report(ohe.inverse_transform(y_pred[:num_to_check]).flatten(), ohe.inverse_transform(y_test[:num_to_check]).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indicative per sample predictions \n",
      " \n",
      "(Sample 1): \n",
      "A great deal of documentation exists on exactly that phenomenon. Especially\n",
      "regarding Vietnam and the Mai Lai (sp?) massacre\n",
      "\n",
      "Not that I'm suggesting that they started it on purpose but even if they\n",
      "now know that they accidentally started (or contributed to it) you can\n",
      "be sure the initial reaction is to lie. Remember the Iranian airliner\n",
      "which the US navy mistook for a fighter and shot down?\n",
      "Correct Labels:['talk.politics.guns'] \n",
      "Pred Labels: ['talk.politics.guns']\n",
      "\n",
      " ################################## \n",
      " \n",
      "(Sample 2): \n",
      "\n",
      "True.\n",
      "\n",
      "\n",
      "No more risk than smaller stashes unless the stash is somehow confined so\n",
      "the heat from early ignitions could somehow bulk-heat the remainder.\n",
      "\n",
      "Two  years ago this month my house and office burned.  In my office was my\n",
      "reloading bench.  On the top shelf next to the wooden ceiling was \n",
      "about 100 lbs of smokeless powder, 5 lbs of black powder, several thousand\n",
      "primers and a couple thousand loaded rounds, primarily in .45ACP, .30-20\n",
      "and .308.  The fire was extinguished before the area containing the \n",
      "reloading supplies were fully involved.  There was about 1/2\" of char on\n",
      "the joists, subsequently removed by sandblasting.  Lots of heat in other\n",
      "words.\n",
      "\n",
      "None of the powder kegs ignited.  One 1lb can of pistol powder ignited.\n",
      "No explosion, as the can opened at the seam as it was designed to do.\n",
      "The black powder cans were charred and got so hot the plastic lids\n",
      "completely melted and ran down inside.  The smokless powder was\n",
      "contained mostly in 8 lb cardboard or metal kegs.  The kegs were charred\n",
      "badly enough that the paper labels burned completely off and in the case\n",
      "of the metal cans, the plastic lids melted completely away.\n",
      "\n",
      "Many of the rounds cooked off.  They were in close proximity to wood\n",
      "on all sides so the effects were easy to observe.  In most cases with the\n",
      "rifle ammo, the cartridge cases ruptured in the middle.  Many bullets were\n",
      "found still in the neck.  Small shards of brass were lightly stuck into \n",
      "the wood.  Lightly enough that brushing them with a fingertip would usually\n",
      "dislodge them.  Primers generally popped out of the primer pockets.\n",
      "The .45ACP rounds that cooked off left empty cases and bullets laying around.\n",
      "No dents were observed above the storage area, indicating the bullets\n",
      "left the cases slowly enough not to be a hazard.\n",
      "\n",
      "Ordinary small arms ammo is NOT a hazard when cooking off regardless\n",
      "of what the FBI says.  \n",
      "\n",
      "John\n",
      "\n",
      "Correct Labels:['talk.politics.guns'] \n",
      "Pred Labels: ['talk.politics.guns']\n",
      "\n",
      " ################################## \n",
      " \n",
      "(Sample 3): I am looking for statistics on the prevalence of disorders that are\n",
      "treatable with Botulinum Type A.  These disorders include: facial\n",
      "dyskinesia, meige syndrome, hemifacial spasm, apraxia of eyelid openeing,\n",
      "aberrant regeneration of the facial nerve, facial paralysis, strabismus,\n",
      "spasmodic torticollis, muscle spasm, occupational dystonia (i.e. writers\n",
      "cramp, etc.), spasmodic dysphonia, and temporal mandibular joint disease.\n",
      "\n",
      "I realize many of the disorders I listed (such as \"muscle spasm\" !!) are\n",
      "vaguely defined and may encompass a wide range of particular disorders.  My\n",
      "apologies; the list was provided to me as is.  I have some numbers, but not\n",
      "reliable.  \n",
      "\n",
      "Any ideas on sources or, even bbetter, any actual figures (with source\n",
      "listed)?\n",
      "\n",
      "Many thanks,\n",
      "\n",
      "- Meg\n",
      "Correct Labels:['sci.med'] \n",
      "Pred Labels: ['sci.med']\n",
      "\n",
      " ################################## \n",
      " \n",
      "(Sample 4): [By default, followups to 3 newsgroups.]\n",
      "\n",
      "A short excerpt:\n",
      "\n",
      "[...]\n",
      "Correct Labels:['alt.atheism'] \n",
      "Pred Labels: ['talk.politics.guns']\n",
      "\n",
      " ################################## \n",
      " \n",
      "(Sample 5): \n",
      "I don't like the term \"quack\" being applied to a licensed physician David.\n",
      "Questionable conduct is more appropriately called unethical(in my opinion).\n",
      "I'll give you some examples.\n",
      "\n",
      "\t1. Prescribing controlled substances to patients with no \n",
      "\t   demonstrated need(other than a drug addition) for the medication.\n",
      "\n",
      "\t2. Prescribing thyroid preps for patients with normal thyroid \n",
      "\t   function for the purpose of quick weight loss.\n",
      "\n",
      "\t3. Using laetril to treat cancer patients when such treatment has \n",
      "\t   been shown to be ineffective and dangerous(cyanide release) by \n",
      "\t   the NCI.\n",
      "\n",
      "These are errors of commission that competently trained physicians should \n",
      "not committ but sometimes do.  There are also errors of omission(some of \n",
      "which result in malpractice suits).  I don't think that using anti-fungal \n",
      "agents to try to relieve discomfort in a patient who you suspect may be \n",
      "having a problem with candida(or another fungal growth) is an error of \n",
      "commission or omission.  Healers have had a long history of trying to \n",
      "relieve human suffering.  Some have stuck to standard, approved procedures,\n",
      "others have been willing to try any reasonable treatment if there is a \n",
      "chance that it will help the patient.  The key has to be tied to the \n",
      "healer's oath, \"I will do no harm\".  But you know David that very few \n",
      "treatments involve no risk to the patient.  The job of the physician is a \n",
      "very difficult one when risk versus benefit has to be weighed.  Each \n",
      "physician deals with this risk/benefit paradox a little differently.  Some \n",
      "are very conservative while others are more agressive.  An agressive \n",
      "approach may be more costly to the patient and carry more risk but as long \n",
      "as the motive is improving the patient's health and not an attempt to rake \n",
      "in lots of money(through some of the schemes that have been uncovered in \n",
      "the medicare fraud cases), I don't see the need to label these healers as \n",
      "quacks or even unethical.\n",
      "\n",
      "What do I reserve the term quack for?  Pseudo-medical professionals.  \n",
      "These people lurk on the fringes of the health care system waiting for the \n",
      "frustrated patient to fall into their lair.  Some of these individuals are \n",
      "really doing a pretty good job of providing \"alternative\" medicine.  But \n",
      "many lack any formal training and are in the \"business\" simply to make a \n",
      "few fast bucks.   While a patient can be reasonably assured of getting \n",
      "competent care when a liscenced physician is consulted, this alternative \n",
      "care area is really a buyer's beware arena.  If you are lucky, you may find \n",
      "someone who can help you.  If you are unlucky, you can loose a lot of \n",
      "money and develop severe disease because of the inability of these pseudo-\n",
      "medical professional to diagnose disease(which is the fortay of the \n",
      "liscened physicians).\n",
      "\n",
      "I hope that this clears things up David.\n",
      "Correct Labels:['sci.med'] \n",
      "Pred Labels: ['sci.med']\n",
      "\n",
      " ################################## \n",
      " \n",
      "(Sample 6): #In article <1r0fpv$p11@horus.ap.mchp.sni.de>\n",
      "# \n",
      "#(Deletion)\n",
      "#>#      Point: Morals are, in essence, personal opinions. Usually\n",
      "#>#(ideally) well-founded, motivated such, but nonetheless personal. The\n",
      "#>#fact that a real large lot of people agree on some moral question,\n",
      "#>#sometimes even for the same reason, does not make morals objective; it\n",
      "#>#makes humans somewhat alike in their opinions on that moral question,\n",
      "#>#which can be good for the evolution of a social species.\n",
      "#>\n",
      "#>And if a \"real large lot\" (nice phrase) of people agree that there is a\n",
      "#>football on a desk, I'm supposed to see a logical difference between the two?\n",
      "#>Perhaps you can explain the difference to me, since you seem to see it\n",
      "#>so clearly.\n",
      "#>\n",
      "#(rest deleted)\n",
      "# \n",
      "#That's a fallacy, and it is not the first time it is pointed out.\n",
      "\n",
      "It's not a fallacy - note the IF.   IF a supermajority of disinterested people \n",
      "agree on a fundamantal value (we're not doing ethics YET Benedikt), then what \n",
      "is the difference between that and those people agreeing on a trivial\n",
      "observation?\n",
      "\n",
      "#For one, you have never given a set of morals people agree upon. Unlike\n",
      "#a football. Further, you conveniently ignore here that there are\n",
      "#many who would not agree on tghe morality of something. The analogy\n",
      "#does not hold.\n",
      "\n",
      "I have, however, given an example of a VALUE people agree on, and explained\n",
      "why.  People will agree that their freedom is valuable.  I have also\n",
      "stated that such a value is a necessary condition for doing objective\n",
      "ethics - the IF assertion above.  And that is what I'm talking about, there\n",
      "isn't a point in talking about ethics if this can't be agreed.\n",
      "\n",
      "#One can expect sufficiently many people to agree on its being a football,\n",
      "#while YOU have to give the evidence that only vanishing number disagrees\n",
      "#with a set of morals YOU have to give.\n",
      "\n",
      "I'm not doing morals (ethics) if we can't get past values.  As I say,\n",
      "the only cogent objection to my 'freedom' example is that maybe people\n",
      "aren't talking about the same thing when they answer that it is valuable.\n",
      "Maybe not, and I want to think about this some, especially the implications\n",
      "of its being true.\n",
      "\n",
      "#Further, the above is evidence, not proof. Proof would evolve out of testing\n",
      "#your theory of absolute morals against competing theories.\n",
      "\n",
      "Garbage.  That's not proof either.\n",
      "\n",
      "#The above is one of the arguments you reiterate while you never answer\n",
      "#the objections. Evidence that you are a preacher.\n",
      "\n",
      "Name that fallacy.\n",
      "Correct Labels:['alt.atheism'] \n",
      "Pred Labels: ['alt.atheism']\n",
      "\n",
      " ################################## \n",
      " \n",
      "(Sample 7): \n",
      "satire \\'sa-tir\\ n [MF or L; MF, fr. L _satura_, _satira_, fr. (lanx)\n",
      "satura full plate, medley, fr. fem. of _satur_ sated; akin to L\n",
      "_satis_ enough - more at SAD](1509) 1: a literary work holding up\n",
      "human vices and follies to ridicule or scorn.  2: trenchent wit,\n",
      "irony, or sarcasm used to expose and discredit vice or folly.  syn see\n",
      "WIT.\n",
      "\n",
      "\t\t\t\t\t\t\tspl\n",
      "Correct Labels:['talk.politics.guns'] \n",
      "Pred Labels: ['alt.atheism']\n",
      "\n",
      " ################################## \n",
      " \n",
      "(Sample 8): :>Sounds to me like someone was pulling your leg.  There is only one way for\n",
      ":>pregnancy to occur: intercourse.  These days however there is also\n",
      ":>artificial insemination and implantation techniques, but we're speaking of\n",
      ":>\"natural\" acts here.  It is possible for pregnancy to occur if semen is\n",
      ":>deposited just outside of the vagina (i.e. coitus interruptus), but that's\n",
      ":>about at far as you can get.  Through clothes -- no way.  Better go talk\n",
      ":>to your biology teacher.\n",
      ":\n",
      ": what is the likely hood of conception if sperm is deposited just outside\n",
      ":the vagina?  ie.  __% chance.\n",
      ": -------------------------------------------------------------------------\n",
      "\n",
      "Hmmm.... I really don't know.  Probably quite low overall.  Why don't we\n",
      "get a couple hundred willing couples together and find out ;->\n",
      "\n",
      "Correct Labels:['sci.med'] \n",
      "Pred Labels: ['sci.med']\n",
      "\n",
      " ################################## \n",
      " \n",
      "(Sample 9): \n",
      "\n",
      "Nice touch - using the word *seem*.\n",
      "-- \n",
      "Dave Feustel N9MYI <feustel@netcom.com>\n",
      "Correct Labels:['talk.politics.guns'] \n",
      "Pred Labels: ['alt.atheism']\n",
      "\n",
      " ################################## \n",
      " \n",
      "(Sample 10): : Actually I am entering vet school next year, but the question is \n",
      ": relevant for med students too.\n",
      "\n",
      ": Memorizing large amounts has never been my strong point academically.\n",
      ": Since this is a major portion of medical education -- anatomy, \n",
      ": histology, pathology, pharmacology, are for the most part mass \n",
      ": memorization -- I am a little concerned.  As I am sure most \n",
      ": med students are.\n",
      "\n",
      ": Can anyone suggest techniques for this type of memorization?  I \n",
      ": have had reasonable success with nemonics and memory tricks like\n",
      ": thinking up little stories to associate unrelated things.  But I have\n",
      ": never applied them to large amounts of \"data\".\n",
      "\n",
      ": Has anyone had luck with any particular books, memory systems, or\n",
      ": cheap software?   \n",
      "\n",
      ": Can you suggest any helpful organizational techniques?  Being an\n",
      ": older student who returned to school this year, organization (another\n",
      ": one of my weak points) has been a major help to my success.\n",
      "\n",
      ": Please no griping about how all you have to do is \"learn\" the material\n",
      ": conceptually.  I have no problem with that, it is one of my strong \n",
      ": points.  But you can't get around the fact that much of medicine is\n",
      ": rote memorization.  \n",
      "\n",
      ": Thanks for your help.\n",
      "The only suggestion i can think of off the top of my head is get a large\n",
      "supply of index cards and memorize small amounts of info at a time, making\n",
      "flash cards and quesitons. Everytime i get a question wrong I always\n",
      "manage to get the damn thing right the next time \n",
      "\n",
      "Correct Labels:['sci.med'] \n",
      "Pred Labels: ['sci.med']\n",
      "\n",
      " ################################## \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"Indicative per sample predictions \\n \")\n",
    "y_pred_labels = model.predict_with_labels(X_test, y_pred)\n",
    "for sample_index, labels in enumerate(y_pred_labels[:num_to_check]):\n",
    "    cur_test_labels = sorted(\n",
    "        [\n",
    "            all_labels_list[index_nonzero]\n",
    "            for index_nonzero in y_test[sample_index].flatten().nonzero()[0]\n",
    "        ]\n",
    "    )\n",
    "    print(\n",
    "        f\"(Sample {sample_index + 1}): {X_test[sample_index]}\\nCorrect Labels:{cur_test_labels} \\nPred Labels: {sorted(labels)}\"\n",
    "    )\n",
    "    print(\"\\n ################################## \\n \")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
